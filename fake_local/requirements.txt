torch>=2.2        # built with CUDA 12 for A100
torchvision>=0.17
transformers>=4.39
torchxrayvision>=1.3
scikit-learn>=1.4
nltk>=3.9
rouge-score>=0.1.2
matplotlib>=3.8
pandas>=2.2
numpy>=1.26
tqdm>=4.66
Pillow>=10.2
pyyaml>=6.0        # used in run_pipeline for config dumps
huggingface-hub>=0.22  # pulled indirectly but best to pin
sentencepiece>=0.2     # required by many HF tokenizers
