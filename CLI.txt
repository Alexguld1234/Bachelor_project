At the moment, i can make a CLI configuration like this.
| Argument                 | Type     | Default              | Options / Notes |
|--------------------------|----------|-----------------------|-----------------|
| `--name`                 | `str`    | *(required)*          | Used for run naming/logging |
| `--encoder`              | `str`    | `resnet`              | `resnet`, `densenet`, `scratch_encoder` |
| `--decoder`              | `str`    | `gpt2`                | `gpt2`, `biogpt`, `scratch_decoder` |
| `--training_phases`      | `str`    | `classification_then_text` | `classification_only`, `classification_then_text`, `text_only` |
| `--epochs_classification`| `int`    | `50`                  | Number of epochs for classification phase |
| `--epochs_text_generation`| `int`   | `50`                  | Number of epochs for generation phase |
| `--batch_size`           | `int`    | `32`                  | Applies to all data loaders |
| `--learning_rate`        | `float`  | `2e-5`                | Learning rate for Adam optimizer |
| `--num_datapoints`       | `int`    | `50000`               | Total number of samples to load from dataset |
| `--save_path`            | `str`    | `./runs` *(or your own default)* | Directory to save model checkpoints and logs |
| `--repetition_penalty`   | `float`  | `1.2`                 | For text generation (prevents repetitive outputs) |
| `--top_k`                | `int`    | `50`                  | Top-K sampling during generation |
| `--top_p`                | `float`  | `0.95`                | Top-P (nucleus) sampling during generation |
| `--max_length`           | `int`    | `128`                 | Maximum length of generated report (in tokens) |
| `--freeze_encoder`       | `flag`   | *not set by default*  | Freeze encoder weights during generation phase |


I want to add a few changes
setup: str defaults=local, options = hpc/local, are we working on local or hpc
img_size int defaults to 224, if set to 224, the transform.resize is gonna be 224 by 224.
And also the savepath, i want to give a name like "bachelor_runs" and then depending on {setup} i find the place, where the data loads from, so D:\ or  /work3/s224228/ to save it there in a folder given by the save_path variable.
